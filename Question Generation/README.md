# Question Generation System

Automated MCQ generation for Grade 3 mathematics using LLMs with Langfuse tracing.

## Quick Start

```bash
# 1. Activate Python 3.13 environment  
cd "/workspaces/github-com-anirudhs-ti-edullm-experiments/Question Generation"
source venv_py313/bin/activate

# 2. Run generation
cd scripts

# Test with 2 questions (~1 minute)
python generate_questions.py 2 42

# Full generation with 30 questions (~10-15 minutes)
python generate_questions.py 30 42

# Custom: N questions with seed S
python generate_questions.py N S
```

## What's New (Latest Version)

âœ… **Langfuse v3 tracing enabled** - All LLM calls are now traced  
âœ… **Consolidated to 2 files** - Simplified codebase (was 11 files, now 2!)  
âœ… **Python 3.13** - Fixed compatibility issues  
âœ… **@observe decorators** - Clean tracing with Langfuse v3 API

## File Structure

```
Question Generation/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_questions.py  # Main script (run this!)
â”‚   â”œâ”€â”€ utils.py               # Helper functions
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ system_a_plan_generation.txt
â”‚       â””â”€â”€ system_b_question_generation.txt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ composed_substandards.json
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ generated_questions_*.json
â”œâ”€â”€ venv_py313/                 # Python 3.13 virtual environment
â””â”€â”€ .env                        # API keys (Gemini, Langfuse)
```

## Output

Questions saved to: `outputs/generated_questions_TIMESTAMP.json`

Format:
```json
{
  "subject": "math",
  "grade": "3",
  "type": "mcq",
  "generated_questions": [
    {
      "id": "q1",
      "type": "mcq",
      "question": "...",
      "answer": "C",
      "answer_explanation": "...",
      "answer_options": {"A": "...", "B": "...", "C": "..."},
      "skill": {...}
    }
  ],
  "metadata": {...}
}
```

## Langfuse Tracing

âœ… **Enabled** - View traces at https://cloud.langfuse.com

Traces include:
- `generate_question_for_substandard` - Overall question generation
- `format_to_scaffolding` - Format conversion  
- `generate_plan` - System A (plan generation)
- `generate_question` - System B (final question)

## Configuration

Edit `.env` file:
```
GEMINI_API_KEY=your_key_here
LANGFUSE_SECRET_KEY=your_key_here
LANGFUSE_PUBLIC_KEY=your_key_here
```

## System Architecture

```
Load Data â†’ Get Misconceptions â†’ For each substandard:
  â”‚
  â”œâ”€> Convert Format to Scaffolding (LLM + @observe)
  â”œâ”€> Generate Plan with System A (LLM + @observe)  
  â””â”€> Generate Question with System B (LLM + @observe)
       â”‚
       â””â”€> Save to JSON
```

## Notes

- â±ï¸ **Rate Limits**: Gemini API has 10 requests/minute  
- ğŸ”„ **Auto Retry**: Automatically retries on rate limits
- ğŸ“Š **Tracing**: All LLM calls logged to Langfuse
- âœ… **Tested**: 2/2 questions generated successfully

## When Done

```bash
deactivate
```

That's it! ğŸ‰
